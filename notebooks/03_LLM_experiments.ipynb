{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f320a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ollama\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f72173a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnl_data_dir = '../FinalDataset'\n",
    "rslt_dir = '../models&results'\n",
    "llm_model = 'llama3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa970940",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_df = pd.read_csv(os.path.join(fnl_data_dir, 'trainFinal.csv')).dropna()\n",
    "    test_df = pd.read_csv(os.path.join(fnl_data_dir, 'testFinal.csv')).dropna()\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Cleaned data files not found in '{fnl_data_dir}'.\")\n",
    "    print(\"Please run Notebook 1 first to generate these files.\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "942f0b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-Shot Summaries: 100%|██████████| 1776/1776 [1:56:37<00:00,  3.94s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot LLM summaries saved to '../models&results/llm_zero_shot_summaries.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "zero_shot_summaries = []\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Zero-Shot Summaries\"):\n",
    "    prompt = f\"\"\"\n",
    "    Summarize the following emotionally sensitive dialogue in a single, concise sentence.\n",
    "    The primary emotion of the dialogue is: {row['emotion']}\n",
    "\n",
    "    Dialogue:\n",
    "    {row['dialogue']}\n",
    "\n",
    "    Summary:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = ollama.generate(model=llm_model, prompt=prompt)\n",
    "        summary = response['response'].strip()\n",
    "        zero_shot_summaries.append({'conv_id': row['conv_id'], 'generated_summary': summary})\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying Ollama for conv_id {row['conv_id']}: {e}\")\n",
    "        zero_shot_summaries.append({'conv_id': row['conv_id'], 'generated_summary': 'OLLAMA_ERROR'})\n",
    "\n",
    "# Save the results\n",
    "zero_shot_results_df = pd.DataFrame(zero_shot_summaries)\n",
    "zero_shot_results_path = os.path.join(rslt_dir, 'llm_zero_shot_summaries.csv')\n",
    "zero_shot_results_df.to_csv(zero_shot_results_path, index=False)\n",
    "print(f\"Zero-shot LLM summaries saved to '{zero_shot_results_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f29e8158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING EXPERIMENT: RAG (FEW-SHOT) LLM (llama3)\n",
      "\n",
      "building the knowledge base for RAG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/48/40cdcp9j2t55h9l2wgznkpgm0000gn/T/ipykernel_43288/1240058258.py:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vector store...\n",
      "Vector store created successfully.\n"
     ]
    }
   ],
   "source": [
    "print(f\"STARTING EXPERIMENT: RAG (FEW-SHOT) LLM ({llm_model})\")\n",
    "\n",
    "#Build the Knowledge Base for Retrieval\n",
    "print(\"\\nbuilding the knowledge base for RAG...\")\n",
    "\n",
    "embedding_model_name = \"all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "print(\"Creating vector store...\")\n",
    "vector_store = FAISS.from_texts(texts=train_df[\"dialogue\"].tolist(),embedding=embeddings)\n",
    "print(\"Vector store created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1c54e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rag_prompt_template = \"\"\"\n",
    "INSTRUCTION: You are an expert in summarizing emotionally sensitive conversations.\n",
    "Use the following three examples of dialogues and their summaries as a guide.\n",
    "\n",
    "EXAMPLE 1:\n",
    "Dialogue: {example_dialogue_1}\n",
    "Summary: {example_summary_1}\n",
    "\n",
    "EXAMPLE 2:\n",
    "Dialogue: {example_dialogue_2}\n",
    "Summary: {example_summary_2}\n",
    "\n",
    "EXAMPLE 3:\n",
    "Dialogue: {example_dialogue_3}\n",
    "Summary: {example_summary_3}\n",
    "\n",
    "Now, using these examples as a guide, summarize the following new dialogue in a single, concise sentence.\n",
    "The primary emotion of the new dialogue is: {emotion}\n",
    "\n",
    "New Dialogue:\n",
    "{dialogue}\n",
    "\n",
    "Final Summary:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7fc8480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/48/40cdcp9j2t55h9l2wgznkpgm0000gn/T/ipykernel_43288/924451446.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=llm_model)\n",
      "/var/folders/48/40cdcp9j2t55h9l2wgznkpgm0000gn/T/ipykernel_43288/924451446.py:8: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  rag_chain = LLMChain(llm=llm, prompt=rag_prompt)\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=llm_model)\n",
    "rag_prompt = PromptTemplate(\n",
    "    template=rag_prompt_template,\n",
    "    input_variables=[\"example_dialogue_1\", \"example_summary_1\",\n",
    "                     \"example_dialogue_2\", \"example_summary_2\",\n",
    "                     \"example_dialogue_3\", \"example_summary_3\",\n",
    "                     \"emotion\", \"dialogue\"])\n",
    "rag_chain = LLMChain(llm=llm, prompt=rag_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5815b2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAG Summaries: 100%|██████████| 1776/1776 [3:19:16<00:00,  6.73s/it]  \n"
     ]
    }
   ],
   "source": [
    "rag_summaries = []\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"RAG Summaries\"):\n",
    "    retrvd_docs = vector_store.similarity_search(row['dialogue'], k=3)\n",
    "    retrvd_eg = []\n",
    "    for doc in retrvd_docs:\n",
    "        original_row = train_df[train_df['dialogue'] == doc.page_content].iloc[0]\n",
    "        retrvd_eg.append({\"dialogue\": original_row['dialogue'],\"summary\": original_row['target_summary']})\n",
    "\n",
    "    chain_inputs = {\n",
    "        \"example_dialogue_1\": retrvd_eg[0]['dialogue'],\n",
    "        \"example_summary_1\": retrvd_eg[0]['summary'],\n",
    "        \"example_dialogue_2\": retrvd_eg[1]['dialogue'],\n",
    "        \"example_summary_2\": retrvd_eg[1]['summary'],\n",
    "        \"example_dialogue_3\": retrvd_eg[2]['dialogue'],\n",
    "        \"example_summary_3\": retrvd_eg[2]['summary'],\n",
    "        \"emotion\": row['emotion'],\n",
    "        \"dialogue\": row['dialogue']}\n",
    "\n",
    "    try:\n",
    "        response = rag_chain.invoke(chain_inputs)\n",
    "        summary = response['text'].strip()\n",
    "        rag_summaries.append({'conv_id': row['conv_id'], 'generated_summary': summary})\n",
    "    except Exception as e:\n",
    "        print(f\"Error with RAG chain for conv_id {row['conv_id']}: {e}\")\n",
    "        rag_summaries.append({'conv_id': row['conv_id'], 'generated_summary': 'RAG_ERROR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "081b033f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG summaries saved to '../models&results/llm_rag_summaries.csv'\n"
     ]
    }
   ],
   "source": [
    "rag_results_df = pd.DataFrame(rag_summaries)\n",
    "rag_results_path = os.path.join(rslt_dir, 'llm_rag_summaries.csv')\n",
    "rag_results_df.to_csv(rag_results_path, index=False)\n",
    "print(f\"RAG summaries saved to '{rag_results_path}'\")                                                                                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c519c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
